\documentclass[12pt,a4paper]{article}
\input{preamble.tex}
\usepackage{matlab-prettifier}
\usepackage{listings}
\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ 
	backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
	basicstyle=\footnotesize,        % the size of the fonts that are used for the code
	breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
	breaklines=true,                 % sets automatic line breaking
	captionpos=b,                    % sets the caption-position to bottom
	commentstyle=\color{mygreen},    % comment style
	deletekeywords={...},            % if you want to delete keywords from the given language
	escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
	extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
	firstnumber=1000,                % start line enumeration with line 1000
	frame=single,	                   % adds a frame around the code
	keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
	keywordstyle=\color{blue},       % keyword style
	language=Octave,                 % the language of the code
	morekeywords={*,...},            % if you want to add more keywords to the set
	%numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
	numbersep=5pt,                   % how far the line-numbers are from the code
	numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
	rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
	showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
	showstringspaces=false,          % underline spaces within strings only
	showtabs=false,                  % show tabs within strings adding particular underscores
	stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
	stringstyle=\color{mymauve},     % string literal style
	tabsize=2,	                   % sets default tabsize to 2 spaces
	title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}
\begin{document}
	\input{titlePage.tex}
	\clearpage
	\section{Exercise: Extract range and angle from scan}
	\subsection{Introduction}
	This section underscores the significance of extracting range and angle information from scanning data, a critical component in localization methodologies. Localization is foundational in robotics, enabling autonomous navigation and interaction with the environment. The TurtleBot platform, utilized both in educational settings and research, serves as a practical example for applying these concepts. This document delineates the approach for two distinct scenarios:
	\begin{itemize}
		\item Implementation on a physical TurtleBot robot.
		\item Application within a simulated environment.
	\end{itemize}
	
	\subsection{Objective}
	The primary goal of this endeavor is to conceive and implement an algorithm that proficiently extracts range-angle coordinates from the scanning data acquired by the TurtleBot. The exercise entails the acquisition of range data, its subsequent processing to ascertain the distance and angle relative to a wall, and the corroboration of these computational findings with empirically measured values. The success of this algorithm is pivotal for the robot to achieve an accurate understanding of its spatial orientation, which is quintessential for effective navigation and task execution.
	
	
	\subsection{Methodology}
	This segment elucidates the systematic procedure adopted for data acquisition and subsequent processing.
	
	\subsubsection{Data Acquisition}
	The acquisition of range data constitutes the first step in our methodology. Utilizing the ROS framework, the TurtleBot's onboard LaserScan sensor gathers two-dimensional scan data, which are encapsulated in the form of a Laserscan (2D) message. The sensor's angular resolution and range precision are instrumental in determining the fidelity of the data captured.
	\\\\
	For calibration and validation purposes, the TurtleBot is meticulously positioned at a predetermined distance and angle with respect to a well-defined wall. This setup ensures that the range data collected are grounded in a known reference frame, which is essential for the subsequent stages of data analysis.
	\\\\
	\textit{Note: It would be beneficial to include a diagram here that visually represents the TurtleBotâ€™s positioning relative to the wall, showing the angle of incidence and the specific region of the wall being scanned. This would help clarify the setup and expected data collection geometry.}
	
	\subsubsection{Sensor Calibration}
	Prior to the initiation of data acquisition, calibrating the sensor is paramount to ensure the precision of the measurements. Calibration encompasses the fine-tuning of sensor parameters to rectify any systematic errors, thus harmonizing the sensor's output with the established reference distance. This procedure is iterated until the deviation of the sensor's readings from the expected values is minimized.
	
	\paragraph{Error Differentiation}
	In the discourse on errors, it is essential to differentiate between systematic and random errors. Systematic errors are consistent and directional biases that can be corrected through calibration. In contrast, random errors manifest as unpredictable fluctuations that calibration cannot eliminate. The random errors are inherent in any measurement and can be mitigated through statistical methods such as averaging over multiple observations.
	
	
	\subsubsection{Algorithm Development}
	Detail the development of the algorithm for extracting range-angle coordinates. Discuss the implementation of line fitting or similar techniques to enhance robustness against irregularities on or near the wall.
	
	\subsection{Experimentation and Testing}
	\subsubsection{Algorithm Testing}
	Explain how the algorithm is tested, including the procedure for driving the robot along a wall at a fixed distance and adjusting its driving angle to maintain this distance.
	
	\subsubsection{Optional Enhancements}
	Discuss optional methods for improving algorithm robustness, such as the implementation of k-means clustering or the Hough transform, to focus on fitting lines or planes to the most significant wall area while ignoring corners and other non-relevant features.
	
	\subsection{Results}
	Present the results of the algorithm testing, including comparisons between the extracted data and true measured values. Include any relevant data visualizations or statistical analyses.
	
	\subsection{Discussion}
	Analyze the performance of the developed algorithm, highlighting its strengths and limitations. Discuss any discrepancies between the extracted data and true values, and suggest possible explanations and improvements.
	
	\subsection{Conclusion}
	Summarize the findings of the exercise, emphasizing the importance of accurate range and angle data extraction in localization methods. Reflect on the potential applications of this work in robotics and future research directions.
	
	\subsection{Simulation of Turtlebot}
	In this section the konfiguration for the simulated Turtlebot will be shown.
	\subsubsection{Simulation environment}
	Figure \ref{fig:fig1} is showing Gazebo and Turtlebot started up from the terminal by using following command in the terminal \texttt{roslaunch turtlebot3\_gazebo turtlebot3\_house.launch}
	\begin{figure}[!h]
		\centering
		\includegraphics[width=\linewidth]{fig1.png}
		\caption{Simulation environment in Ubuntu (Fosscal), Gazebo V11 and Turtlebot3}
		\label{fig:fig1}
	\end{figure}
	
	\noindent The Turtlebot model is missing it's camera and therefore we need to terminate the session and navigate to the following folder \texttt{catkin\_ws} for then be using the command \texttt{source devel/setup.bash}. The purpose of this command it is to do the environment setting. We relaunch the simulation by following command:
	
	\noindent\texttt{roslaunch turtlebot3\_gazebo}\texttt{turtlebot3\_house.launch}.
	\\\\
	To verify that the camera and Lidar sensor is working then we run \texttt{rostopic list} (showing the list of ROS-topics) followed up by \texttt{rostopic echo /scan} (topic for Lidar) and \texttt{rostopic echo /camera/image\_raw} (topic for camera). By looking at the data stream in figure \ref{fig:fig5} then we can verify that the configuration is done and our environment is running.
	\begin{figure}[!h]
		\centering
		\includegraphics[width=\linewidth]{fig4.png}
		\caption{Showing rostopic list}
		\label{fig:fig4}
	\end{figure}
	\begin{figure}[!h]
		\centering
		\includegraphics[width=\linewidth]{fig5.png}
		\caption{/scan data stream}
		\label{fig:fig5}
	\end{figure}
	\subsubsection{Matlab script}
	In this section there will be an introduction to the Matlab script for getting the values from the Lidar which is published on the topic \texttt{/scan}.
	
	\begin{verbatim}
	% Initialize ROS
	rosshutdown;
	rosinit('http://localhost:11311'); % Replace with your ROS master's URI
	
	% Create Subscriber for /scan Topic
	scanSub = rossubscriber('/scan', 'sensor_msgs/LaserScan');
	
	% Create Publisher for cmd_vel Topic
	cmdVelPub = rospublisher('/cmd_vel', 'geometry_msgs/Twist');
	
	% Define an empty Twist message to control the robot
	twistMsg = rosmessage(cmdVelPub);
	
	% Loop that runs until the script is stopped
	while true
		% Receive scanning data
		scanData = receive(scanSub);
		
		% Calculate the angles for each distance measurement
		angles = scanData.AngleMin : scanData.AngleIncrement : scanData.AngleMax;
		
		% Find the average distance to the wall on the right side
		rightIndices = find(angles >= -pi/2 & angles <= pi/2);
		rightDistances = scanData.Ranges(rightIndices);
		rightDistance = min(rightDistances);
		
		% Adjust the robot's velocities based on the distance to the wall
		if rightDistance < 1.0 % If the distance is too close, turn left
			twistMsg.Linear.X = 0.2; % Forward speed
			twistMsg.Angular.Z = 0.5; % Left turn
		else % Otherwise, follow the wall on the right side
			twistMsg.Linear.X = 0.5; % Forward speed
			twistMsg.Angular.Z = -0.1; % Right turn
		end
		
		% Send the Twist message to the robot
		send(cmdVelPub, twistMsg);
		
		% Wait for a short moment
		pause(0.1);
	end
	
	% Close the ROS connection
	rosshutdown;
	\end{verbatim}
	A picture of the Turtlebot following the wall.
	\begin{figure}[!h]
		\centering
		\includegraphics[width=\linewidth]{fig6.png}
		\caption{Turtlebot following the wall at the right side}
		\label{fig:fig6}
	\end{figure}
	\subsection{Physical TurtleBot Configuration}
	\subsubsection{Network Configuration for TurtleBot and PC}
	This section describes the network setup for the physical TurtleBot.
	\subsubsection{Connecting to the TurtleBot3 from PowerShell}
	To connect to the TurtleBot, connect to its WiFi network with the following credentials:
	\begin{itemize}
		\item \textbf{SSID:} turtlebot
		\item \textbf{Password:} turtlebot3
	\end{itemize}
	In PowerShell, initiate the SSH connection by typing:
	\begin{center}
		\textit{ssh ubuntu@192.168.72.251} with the password: \textit{turtlebot}
	\end{center}
	\noindent\textbf{Matlab script for whole program}
	\begin{lstlisting}
		setenv('ROS_MASTER_URI','http://192.168.179.100:11311');
		setenv('ROS_IP','192.168.179.38');
		rosshutdown()
		rosinit('http://192.168.179.100:11311','NodeHost','192.168.179.38')
		
		%% Subscriber and publisher setup
		vel_pub = rospublisher('/cmd_vel');
		scansub = rossubscriber('/scan');
		pos_sub = rossubscriber('/tf');
		
		%% Controller setup
		controller = controllerPurePursuit;
		controller.DesiredLinearVelocity = 0.2;
		controller.MaxAngularVelocity = 2;
		
		%We found that the robot is relatively stable with a LookAheadDistance of
		%0.4
		controller.LookaheadDistance = 0.4;
		
		%Since we're using the reference frame of the LIDAR position and angle are
		%always 0
		robotCurrentPose = [0; 0; 0];
		
		while(1)
			%% Data retrieval
			scan = receive(scansub);
			cart = readCartesian(scan);
			
			hold on
			xlim([-4 4])
			ylim([-4 4])
			
			x = cart(:, 1);  % x-pos
			d = cart(:, 2);  % y-pos
			
			% Filter out points with y coordinates above 0 (to the right of the robot)
			filtered_indices = d <= 0;
			x = x(filtered_indices);
			d = d(filtered_indices);
			
			%% Fitting the line of the wall and plotting it
			
			mdl = fitlm(x,d);
			coef=mdl.Coefficients.Estimate;
			
			plot(x, (coef(1) + coef(2)*x), 'r')
			
			% Calculate the distance from the robot to the line to check if
			% distance is ~0.5 meter
			distance = abs(coef(1)) / sqrt(1 + coef(2)^2);
			
			fprintf('Closest distance from (0,0) to the line: %f\n', distance);
			
			%Defining a point to aim for 0.5 meters out from the wall and 1 meter
			%ahead
			aim_point = [1 0.5+(coef(2)*1+coef(1))];
			
			plot(aim_point(1),aim_point(2),'b.');
			
			%Setting the controller to go towards the aim-point
			controller.Waypoints = aim_point;
			[v, w] = controller(robotCurrentPose);
			update_vel(v,w,vel_pub)		
		end
		
		function [true] = update_vel(v,w,vel_pub)
		
			%Very simple function. We get a new linear and angular velocity from the
			%controller and output it to the cmd_vel topic.
			twistmsg = rosmessage(vel_pub);
			
			twistmsg.Angular.Z = w;
			twistmsg.Linear.X = v;
			
			send(vel_pub,twistmsg);
		end
	\end{lstlisting}
\end{document}